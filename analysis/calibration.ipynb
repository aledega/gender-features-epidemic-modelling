{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries and functions\n",
    "import sys\n",
    "sys.path.append(\"../functions/\")\n",
    "from model import compute_ifr_bygender\n",
    "from matrices import create_matrices_dict\n",
    "from calibration import calibrate_model, run_posterior_sampling\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import os.path\n",
    "\n",
    "# global variables\n",
    "n_comp = 6                                                                                 # number of compartments\n",
    "age_groups = ['20-29', '30-39', '40-49', '50-59', '60+']                                   # list of strings with age groups \n",
    "age_groups_bins = [20, 30, 40, 50, 60, np.inf]                                             # list of int with age groups extremes \n",
    "n_age = len(age_groups)                                                                    # number of age groups\n",
    "n_gen = 2                                                                                  # number of gender groups\n",
    "model_list = ['0', 'I', 'B', 'IB', 'C', 'CI', 'CB', 'CIB']                                 # list of strings with model codes \n",
    "n_sim = 1000000                                                                            # number of simulations to perform\n",
    "save_interval = 1000                                                                       # number of simulations after which a saving is performed\n",
    "\n",
    "path_save = '../runs/'                                                                     # path where to save simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA IMPORT\n",
    "\n",
    "# Load the weekly mortality data\n",
    "df_deaths = pd.read_csv('../data/deaths/weekly_deaths.csv')\n",
    "\n",
    "# Load the population array (Nij)\n",
    "with open('../data/population/Nij.json', 'r') as f:\n",
    "    Nij = np.array(json.load(f))\n",
    "\n",
    "# For contact matrices\n",
    "\n",
    "# Load the CoMix contact matrices by zones stratified by both age and gender\n",
    "with open('../data/matrices/CM_zones_dict.json', 'r') as f:\n",
    "    # Load and immediately convert lists back to numpy arrays\n",
    "    CM_zones_dict = {k: np.array(v) for k, v in json.load(f).items()}\n",
    "\n",
    "# Load the CoMix contact matrices by zones stratified only by age\n",
    "with open('../data/matrices/CM_zones_nogender_dict.json', 'r') as f:\n",
    "    # Load and immediately convert lists back to numpy arrays\n",
    "    CM_zones_nogender_dict = {k: np.array(v) for k, v in json.load(f).items()}\n",
    "\n",
    "# Load the POLYMOD contact matrices by zones stratified by both age and gender\n",
    "with open('../data/matrices/CM_polymod_dict.json', 'r') as f:\n",
    "    # Load and immediately convert lists back to numpy arrays\n",
    "    CM_polymod_dict = {k: np.array(v) for k, v in json.load(f).items()}\n",
    "\n",
    "# Load the POLYMOD contact matrices by zones stratified only by age\n",
    "with open('../data/matrices/CM_polymod_nogender_dict.json', 'r') as f:\n",
    "    # Load and immediately convert lists back to numpy arrays\n",
    "    CM_polymod_nogender_dict = {k: np.array(v) for k, v in json.load(f).items()}\n",
    "\n",
    "# Load the pre-processed mobility reduction data to update Polymod matrices\n",
    "df_mob = pd.read_csv('../data/mobility/mobility_changes.csv', index_col='week')\n",
    "\n",
    "# Load data of restrictions by region to update CoMix matrices\n",
    "data_zones_byregion = pd.read_csv('../data/restrictions/zones_byregion.csv', index_col='Region')\n",
    "\n",
    "# Load data of population by region to update CoMix matrices\n",
    "data_population_byregion = pd.read_csv('../data/population/population_byregion.csv', index_col='Region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "t_step = 1                                                          # temporal step (in days)\n",
    "initial_date = datetime(2020, 9, 14)                                # starting date of the simulation\n",
    "end_date = datetime(2021, 2, 21)                                    # ending date of the simulation\n",
    "t_max = int((end_date - initial_date).days * (1/t_step))            # number of days in the simulation\n",
    "\n",
    "mu = 1 / 2.5                                                        # inverse of infectious period\n",
    "epsilon = 1 / 4                                                     # inverse of latent period\n",
    "Delta = 14                                                          # Average number of days of delay of deaths reporting\n",
    "\n",
    "IFR = [0.000309, 0.000844, 0.00161, 0.00595, 0.0328]                # Infectious Fatality Ratio by age group\n",
    "OR_gender = 1.39\n",
    "IFR_gender = compute_ifr_bygender(IFR, OR_gender, Nij)             # Infectious Fatality Ratio by age group and gender\n",
    "\n",
    "initial_cases = 10119                                               # Observed initial number of individuals in L and I compartments (14th Septemeber)\n",
    "\n",
    "threshold = 0.2                                                     # Threshold of calibration metric for acceptance\n",
    "\n",
    "# Define priors\n",
    "prior_dict = {\n",
    "        'i0':  lambda: np.random.randint(int(initial_cases), int(10 * initial_cases)) / Nij.sum(),             # Initial fraction of individuals in L and I compartments\n",
    "        'r0':  lambda: np.random.uniform(0.03, 0.10),                                                          # Initial fraction of recovered individuals\n",
    "        'R01': lambda: np.random.uniform(1.0, 1.7),                                                            # R0 at the beginning of the simulations\n",
    "        'R02': lambda: np.random.uniform(0.5, 1.7),                                                            # R0 on November 6th, 2020\n",
    "        'r_beta': lambda: np.random.uniform(1.0, 1.3)                                                          # Relative susceptibility for males (used if 'B' in model_type).\n",
    "    }\n",
    "\n",
    "# Compute period (initial and final week) on which performing the calibration \n",
    "# initial_week: 2 weeks after initial_date to give the model time to adjust\n",
    "initial_week = (initial_date + timedelta(days=14)).strftime(\"%Y-%W\")\n",
    "initial_week = f\"{int(initial_week[:4]) - 1}-52\" if initial_week.endswith('-00') else initial_week    # adjust for week 00 if necessary\n",
    "\n",
    "# final_week: week of end_date\n",
    "final_week = end_date.strftime(\"%Y-%W\")\n",
    "final_week = f\"{int(final_week[:4]) - 1}-52\" if final_week.endswith('-00') else final_week            # adjust for week 00 if necessary\n",
    "\n",
    "# Define observed weekly deaths for calibration\n",
    "df_deaths = df_deaths.groupby('week')['weekly_deaths'].sum().reset_index()\n",
    "deaths_observed = df_deaths.loc[(df_deaths['week'] >= initial_week) & (df_deaths['week'] <= final_week)]\n",
    "deaths_observed = deaths_observed['weekly_deaths'].values\n",
    "\n",
    "# Create the dictionary of contact matrices \n",
    "CM_dates_gender = create_matrices_dict(initial_date, t_max, t_step, df_mob, data_zones_byregion, data_population_byregion, CM_polymod_dict, CM_zones_dict)\n",
    "CM_dates_nogender = create_matrices_dict(initial_date, t_max, t_step, df_mob, data_zones_byregion, data_population_byregion, CM_polymod_nogender_dict, CM_zones_nogender_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulations_dict = {}\n",
    "\n",
    "# iterate through each model version (e.g., '0', 'I', 'B', 'IB', etc.)\n",
    "for model_string in model_list:\n",
    "    \n",
    "    # define the output file path for saving raw calibration results\n",
    "    output_file = path_save + f'raw/simulations_model_{model_string}.csv'\n",
    "\n",
    "    # select the appropriate Contact Matrices based on model type\n",
    "    # if 'C' is present, use gender-stratified matrices (10x10); otherwise, use age-only (5x5)\n",
    "    if 'C' in model_string:\n",
    "        CM_dates_dict = CM_dates_gender\n",
    "    else:\n",
    "        CM_dates_dict = CM_dates_nogender\n",
    "\n",
    "    # select the appropriate IFR vector/matrix based on model type\n",
    "    # if 'I' is present, use gender-stratified IFR; otherwise, use age-only vector\n",
    "    if 'I' in model_string:\n",
    "        IFR_model = IFR_gender\n",
    "    else:\n",
    "        IFR_model = IFR\n",
    "\n",
    "    # check if simulation results already exist to avoid re-running expensive calibration\n",
    "    if os.path.exists(output_file):\n",
    "        simulations_dict[model_string] = pd.read_csv(output_file)\n",
    "    else:\n",
    "        # run calibration: generates n_sim simulations and saves accepted parameters/outcomes to CSV\n",
    "        simulations_dict[model_string] = calibrate_model(model_string, Nij, CM_dates_dict, initial_date, t_max, t_step, initial_cases, mu, epsilon, IFR_model, Delta, deaths_observed, threshold, n_sim, save_interval, \n",
    "                                                         prior_dict, output_file)\n",
    "    \n",
    "    # parse the 'simulated_deaths' column from JSON strings back into Python lists\n",
    "    simulations_dict[model_string]['simulated_deaths'] = simulations_dict[model_string]['simulated_deaths'].apply(json.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best simulations\n",
    "best_simulations_dict = {}\n",
    "for model_string, df_simulations in simulations_dict.items():\n",
    "    # Filter for error below threshold\n",
    "    df_best_simulations = df_simulations[df_simulations['err']<=threshold].copy().reset_index(drop=True)\n",
    "    best_simulations_dict[model_string] = df_best_simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists for model 0, skipping...\n",
      "File already exists for model I, skipping...\n",
      "File already exists for model B, skipping...\n",
      "File already exists for model IB, skipping...\n",
      "File already exists for model C, skipping...\n",
      "File already exists for model CI, skipping...\n",
      "File already exists for model CB, skipping...\n",
      "File already exists for model CIB, skipping...\n"
     ]
    }
   ],
   "source": [
    "# Configuration parameters\n",
    "n_param_sets = 1000\n",
    "n_sim_per_set = 10\n",
    "\n",
    "# iterate through each model version (e.g., '0', 'I', 'B', 'IB', etc.)\n",
    "for model_string, df_best_simulations in best_simulations_dict.items():\n",
    "\n",
    "    # select the appropriate Contact Matrices based on model type\n",
    "    # if 'C' is present, use gender-stratified matrices (10x10); otherwise, use age-only (5x5)\n",
    "    if 'C' in model_string:\n",
    "        CM_dates_dict = CM_dates_gender\n",
    "    else:\n",
    "        CM_dates_dict = CM_dates_nogender\n",
    "\n",
    "    # select the appropriate IFR vector/matrix based on model type\n",
    "    # if 'I' is present, use gender-stratified IFR; otherwise, use age-only vector\n",
    "    if 'I' in model_string:\n",
    "        IFR_model = IFR_gender\n",
    "    else:\n",
    "        IFR_model = IFR\n",
    "        \n",
    "    # define final path\n",
    "    file_path = path_save + f\"sampled/sampled_simulations_model_{model_string}.pkl.gz\"\n",
    "    \n",
    "    # check if path already exists \n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"File already exists for model {model_string}, skipping...\")\n",
    "    else:\n",
    "        # run posterior sampling function\n",
    "        df_sampled = run_posterior_sampling(model_string, Nij, CM_dates_dict, initial_date, t_max, t_step, mu, epsilon, IFR_model, Delta, df_best_simulations, n_param_sets, n_sim_per_set,\n",
    "                                            file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4dd075416a397a7de0e2de4b175aae2c341c79e68a4ea7bd5f1ed7977c90ec63"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('gender_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
